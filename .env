#-------------------------------------
# Q&A Server address (for client)
SERVER_URL="127.0.0.1"
SERVER_PORT="8000"

#-------------------------------------
# Cache for models
CACHE_DIR='./cache'

#-------------------------------------
# OpenVINO HTML document directory
DOCUMENT_DIR="openvino-html-doc"

#-------------------------------------
# Vector store settings
VECTOR_DB_DIR="./.vectorstore"
VECTOR_DB_POSTFIX="_300_0"

#-------------------------------------
# OpenVINO Settings
MODEL_PRECISION="INT8"          # "FP16", "INT8", "INT4"
INFERENCE_DEVICE="CPU"          # "CPU", "GPU", "GPU.0" (iGPU), "GPU.1" (dGPU)

#-------------------------------------
# LLM Model settings
MODEL_VENDOR="Intel"
MODEL_NAME="neural-chat-7b-v3-1"

MODEL_VENDOR="meta-llama"
MODEL_NAME="Llama-2-7b-chat-hf"

#MODEL_VENDOR="databricks"
#MODEL_NAME="dolly-v2-3b"

#-------------------------------------
# Text embeddings model 
# (the default model for langchain.embeddings.HuggingFaceEmbeddings is all-mpnet-base-v2)
MODEL_EMBEDDINGS = 'jinaai/jina-embeddings-v2-base-en'
#MODEL_EMBEDDINGS = 'sentence-transformers/all-mpnet-base-v2'


#-------------------------------------
# RAG Generation/Pipeline settings
NUM_MAX_TOKENS=140
RAG_CHAIN_TYPE="stuff"      # "stuff", "map_reduce", "map_rerank", "refine"
